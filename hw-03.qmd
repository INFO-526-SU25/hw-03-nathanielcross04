---
title: "HW 03"
subtitle: "INFO 526 Summer 2025"
author: "Nathaniel Cross"
format:
  html:
    embed-resources: true
toc: true
---

SUPPRESS WARNINGS!!!

## 0 - Setup

```{r}
#| label: R Setup

# Install and load packages
if(!require(pacman))
  install.packages("pacman")

pacman::p_load(tidyverse, 
               glue,
               scales,
               countdown,
               ggthemes,
               gt,
               palmerpenguins,
               openintro,
               ggrepel,
               patchwork,
               quantreg,
               janitor,
               colorspace,
               broom,
               fs,
               here,
               openintro,
               gghighlight,
               lubridate,
               dsbox,
               ggridges,
               gtable,
               ggimage,
               png,
               ggpubr
               )

devtools::install_github("tidyverse/dsbox")

# Set theme for ggplot2
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 14))

# Set width of code output
options(width = 65)

# Set figure parameters for knitr
knitr::opts_chunk$set(
  fig.width = 7,        # 7" width
  fig.asp = 0.618,      # the golden ratio
  fig.retina = 3,       # dpi multiplier for displaying HTML output on retina
  fig.align = "center", # center align figures
  dpi = 300             # higher dpi, sharper image
)
```

## 1 - Du Bois challenge.

```{r}
#| label: Question 1 code

# Loading in the data
income <- read_csv("data/income.csv")

income |>
  glimpse()

# Correcting the data
income[1, 6] = 0.1
income[1, 7] = 9.9 # Source: Marcel Hebing, StackOverflow

# Pivoting the data long
income_clean <- income |>
  pivot_longer(
    cols = c("Rent", "Food", "Clothes", "Tax", "Other"), 
    names_to = "category", 
    values_to = "expenditure"
  ) |>
  glimpse()

# Set image
image <- "https://cdn.pixabay.com/photo/2012/12/06/06/27/paper-68829_1280.jpg"

# Releveling factor variables
income_clean <- income_clean |>
  mutate(
    Class = fct_relevel(Class, "$100-200", "$200-300", "$300-400", "$400-500", "$500-750", "$750-1000", "$1000 AND OVER"),
    category = fct_relevel(category, "Rent", "Food", "Clothes", "Tax", "Other"),
    Class = fct_rev(Class),
    category = fct_rev(category)
  )

# Creating cumulative summations
income_clean <- income_clean |>
  group_by(Class) |>
  mutate(label_y = cumsum(expenditure) - 0.5 * expenditure) |>
  ungroup() # Source: R Graphics Codebook


# Prepping labels
income_clean2 <- income_clean|>
  filter(category != "Rent" & category != "Tax")

income_clean2 <- income_clean2 |>
  mutate(
    perc = "%",
    expend2 = glue("{expenditure}{perc}")
  ) 
  
# Plotting
plot <- income_clean |>
  ggplot(aes(x = Class, y = expenditure, fill = category)) +
  geom_col(width = 0.5) +# Source: Geeks for Geeks (https://www.geeksforgeeks.org/r-language/grouped-stacked-and-percent-stacked-barplot-in-ggplot2/) +
    geom_text(data = income_clean2, aes(y = label_y, label = expend2), color = "black", size = 3, family = "mono") + 
  labs(
    y = NULL,
    x = NULL,
    title = "INCOME AND EXPENDITURE OF 150 NEGRO FAMILIES IN ATLANTA, GA., U.S.A."
  ) +
   annotate(
    geom = "text",
    x = c("$100-200", "$200-300", "$300-400", "$400-500", "$500-750"),
    y = c(9.5, 11, 11.5, 9, 6.5),
    label = c("19%", "22%", "23%", "18%", "13%"),
    size = 3,
    color = "white",
    family = "mono"
  ) +
   annotate(
    geom = "text",
    x = c("$200-300", "$300-400", "$400-500", "$500-750", "$750-1000", "$1000 AND OVER"),
    y = c(94, 86.25, 72.75, 63.5, 60, 47.25),
    label = c("4%", "4.5%", "5.5%", "5%", "8%", "4.5%"),
    size = 2,
    color = "black",
    family = "mono"
  ) +
   scale_x_discrete(labels = c("1,000     $1,125 \nAND OVER          ", "$750-1000   $880   ", "$500-750   $547   ", "$400-500   $433.82", "$300-400   $335.66", "$200-300   $249.45", "$100-200   $139.10")) +
  coord_flip(clip = "off") +
  scale_fill_manual(values = c("snow2", "slategray1", "sienna1", "purple", "black")) +
  theme(
    legend.position = "top",
    plot.title.position = "plot",
    plot.title = element_text(size = 10, hjust = 0.5, face = "bold"),
    panel.grid = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_text(size =7),
    text = element_text(family = "mono"),
    legend.title = element_blank(), 
    legend.text  = element_text(size = 9),
    legend.key.size = unit(0.3, "cm") # Source: https://www.tidyverse.org/blog/2024/02/ggplot2-3-5-0-legends/
  )
  
ggbackground(plot, image) # Source: Guangchuang Yu (https://guangchuangyu.github.io/2018/04/setting-ggplot2-background-with-ggbackground/)
```

## 2 - COVID survey - interpret

The visualization deconstructs responses to six statements regarding perceptions of the COVID-19 vaccine and its safety. Responses are measured on a 1-5 Likert scale, with the means depicted in the figure. Error bars are also depicted from the 10th to 90th percentiles of responses per question. Responses are shown on a macro-level first, then classified by identity, such as age, gender, and race (among others). For each statement, there is minor variation by identity group in mean response on the Likert scale; the interesting part of this figure is derived from its depiction of the distributions of each response, which are far less homogeneous. As the surveyed respondents are nursing and medical university students across the United States, most responses indicate high trust in the vaccine and its safety. This holds true for the statements, "I believe the vaccine is safe," "Getting the vaccine makes me feel safer at work," "I am confident in the scientific vetting process for new vaccines," "I trust the information I have received," and "I will recommend the vaccine to others" (abridged for brevity), where all respondents express agreement with the statement (strong or somewhat agree). Less agreement is introduced in response to the statement, "I am concerned about side effects," where agreement is neutral (neither agree nor disagree).

Some of the most intriguing results for me in this plot are located among identity groups with heterogeneous variation in responses between statements. For example, there is high variation in responses to the statement "I believe the vaccine is safe" among Asians (with the 10-90th percentiles encompassing almost the entire scale), however this variation is almost completely eliminated when the same group was asked if they would recommend the vaccine to others. I would have expected similar variation in response to these questions because if one does not find the vaccine safe, I would expect them to be less likely to recommend it. I also find it interesting in comparing variation between statements at the macro level, regardless of identity group. More particularly, in almost every identity group there is high heterogeneity in responses to the "I am concerned about side effects" statement, however much less variation in "I will recommend the vaccine to others" statement. This could be indicative of a stronger sense of community in light of a global pandemic (dependent on when the data were collected). Finally, I find a comparison of nursing and medical students interesting, especially when comparing the distributions of their responses. As both are in the medical field literally learning about the processes involved in designing and selling vaccines, I would have expected the distribution of these responses to be similar, however for all statements but the first and third, the distributions are larger for medical students than nurses. While this difference may not be statistically significant, is makes an interesting comparison and begs the questions as to why.

## 3 - COVID survey - reconstruct

```{r}
#| label: Question 3 code data wrangling

# Loading in data
covid <- read_csv("data/covid-survey.csv")

# Renaming columns to row 1
colnames(covid) <- covid[1,] # Source: https://stackoverflow.com/questions/32054368/use-first-row-data-as-column-names-in-r

# Deleting row 1 (now column names)
remove.rows <- 1
covid <- covid[!(row.names(covid) %in% remove.rows),] # Source: https://www.tutorialspoint.com/how-to-remove-rows-in-an-r-data-frame-using-row-names

# Dimensions of dataset
dim(covid)

# Eliminate rows with all NAs but response ID
covid <- covid |>
  filter(!if_all(-response_id, is.na))

# Dimensions of the dataset
dim(covid)

# Relabel values of columns
covid |>
  glimpse()

covid <- covid |>
    mutate(
      exp_already_vax = recode(exp_already_vax, "0" = 'No', "1" = 'Yes'),      
      exp_flu_vax = recode(exp_flu_vax, "0" = 'No', "1" = 'Yes'),
      exp_profession = recode(exp_profession, "0" = 'Medical', "1" = 'Nursing'),
      exp_gender = recode(exp_gender, "0" = 'Male', "1" = 'Female', "3" = 'Non-binary third gender', "4" = 'Prefer not to say'),
      exp_race = recode(exp_race, "1" = 'American Indian/Alaskan Native', "2" = 'Asian', "3" = 'Black/African American', "4" = 'Native Hawaiian/Other Pacific Islander', "5" = 'White'),
      exp_ethnicity = recode(exp_ethnicity, "1" = 'Hispanic/Latino', "2" = 'Non-Hispanic/Non-Latino'),
      exp_age_bin = recode(exp_age_bin, "0" = '<20', "20" = '21-25', "25" = '26-30', "30" = '>30')
    )

# Dimensions of dataset
dim(covid)

# Calculating mean and percentiles
covid_survey_longer <- covid |>
  pivot_longer(
    cols = starts_with("exp_"),
    names_to = "explanatory",
    values_to = "explanatory_value"
  ) |> # This pivot lengthens the data so that instead of one column for each explanatory variable, there are instead multiple observations of each response, one per explanatory variable. The values of these explanatory variables were pivoted into a new column, explanatory_value.
  filter(!is.na(explanatory_value)) |> # Eliminates NAs from explanatory values.
  pivot_longer(
    cols = starts_with("resp_"),
    names_to = "response",
    values_to = "response_value"
  ) # This pivot again lengthens the data, this time for response variables. This means that for each response variable for each response ID, explanatory variables and their values are listed.

# Display tibble
covid_survey_longer

# Destring response_value
covid_survey_longer$response_value <- as.numeric(as.character(covid_survey_longer$response_value)) # Source: Geeks for Geeks (https://www.geeksforgeeks.org/r-language/convert-data-frame-column-to-numeric-in-r/)

sapply(covid_survey_longer, class)

# Calculating summary statistics for identity groups
covid_survey_summary_stats_by_group <- covid_survey_longer |>
  group_by(explanatory, explanatory_value, response) |>
  summarise(mean = mean(response_value, na.rm = TRUE),
            low = quantile(response_value, 0.1, na.rm = TRUE),
            high = quantile(response_value, 0.9, na.rm = TRUE) # Source: https://tbradley1013.github.io/2018/10/01/calculating-quantiles-for-groups-with-dplyr-summarize-and-purrr-partial/
            )

# Display tibble
covid_survey_summary_stats_by_group

# Calculating summary statistics for all
covid_survey_summary_stats_all <- covid_survey_longer |>
  group_by(response) |>
  summarise(mean = mean(response_value, na.rm = TRUE),
            low = quantile(response_value, 0.1, na.rm = TRUE),
            high = quantile(response_value, 0.9, na.rm = TRUE)
            ) |>
  mutate(
    explanatory = "All",
    explanatory_value = ""
  )

covid_survey_summary_stats_all$explanatory_value <- as.factor(as.character(covid_survey_summary_stats_all$explanatory_value))

sapply(covid_survey_summary_stats_all, class)

# Display tibble
covid_survey_summary_stats_all

# Bind the two summary statistic dataframes together
covid_survey_summary_stats <- bind_rows(covid_survey_summary_stats_all, covid_survey_summary_stats_by_group)

# Display tibble
covid_survey_summary_stats
```

```{r}
#| label: Question 3 code plotting

# Relevel factors
covid_survey_summary_stats <- covid_survey_summary_stats |>
  mutate(
      explanatory_value = fct_rev(fct_relevel(explanatory_value, ">30", "26-30", "21-25", "<20")),
      explanatory = fct_relevel(explanatory, "All", "exp_age_bin", "exp_gender", "exp_race", "exp_ethnicity", "exp_profession", "exp_already_vax", "exp_flu_vax"),
      explanatory_value = fct_relevel(explanatory_value, "Female", "Male", "Non-binary third gender", "Prefer not to say"),
      explanatory_value = fct_relevel(explanatory_value, "American Indian/Alaskan Native", "Asian", "Black/African American", "Native Hawaiian/Other Pacific Islander", "White"),
      explanatory_value = fct_relevel(explanatory_value, "Non-Hispanic/Non-Latino", "Hispanic/Latino"),
      explanatory_value = fct_relevel(explanatory_value, "Medical", "Nursing"),
      explanatory_value = fct_relevel(explanatory_value, "No", "Yes")
  )

# Set labels
covid_survey_summary_stats <- covid_survey_summary_stats |>
    mutate(
      explanatory = recode(explanatory, "exp_age_bin" = 'Age', "exp_gender" = 'Gender', "exp_race" = 'Race', "exp_ethnicity" = 'Ethnicity', "exp_profession" = 'Profession', "exp_already_vax" = 'Had COVID vaccine', "exp_flu_vax" = 'Had flu vaccine this year'),
      response = fct_relevel(response, "resp_safety", "resp_feel_safe_at_work", "resp_concern_safety", "resp_confidence_science",   "resp_trust_info", "resp_will_recommend"),
      response = recode(response, 
                        "resp_safety" = 'Based on my understanding, I believe the vaccine is safe', 
                        "resp_confidence_science" = 'I am confident in the scientific vetting process for the new COVID vaccines', 
                        "resp_feel_safe_at_work" = 'Getting the vaccine will make me feel safer at work', 
                        "resp_will_recommend" = 'I will recommend the vaccine to family, friends, and community members', 
                        "resp_trust_info" = 'I trust the information that I have received about the vaccines',
                        "resp_concern_safety" = 'I am concerned about the safety and side effects of the vaccine')
    )

# Creating the plot
covid_survey_summary_stats |>
ggplot(aes(x = mean, y = factor(explanatory_value))) +
  geom_point(size = 0.75) +
  geom_errorbarh(aes(xmin = low, xmax = high), height = 0.3) +
  facet_grid(
    rows = vars(explanatory), 
    cols = vars(response), 
    scales = "free_y",
    space = "free_y", 
    labeller = labeller(explanatory = label_wrap_gen(15), response = label_wrap_gen(15)) 
    ) +
  scale_x_continuous(breaks = 1:5) +
  labs(
    x = "Mean Likert score\n(Error bars range from 10th to 90th percentile)",
    y = NULL,
  ) +
  theme(
    strip.text = element_text(size = 6),
    strip.text.y = element_text(angle = 0),
    axis.text.y = element_text(size = 6),
    axis.text.x = element_text(size = 6),
    panel.spacing = unit(0, "lines"),
    panel.spacing.x = unit(0.3, "lines"),
    axis.title.x = element_text(size = 8),
    panel.grid = element_blank(),
    strip.background = element_rect(fill = "gray90", color = "black")
  )
```

## 4 - COVID survey - re-reconstruct

```{r}
#| label: Question 4 code

# Calculating summary statistics for identity groups
covid_survey_summary_stats_by_group2 <- covid_survey_longer |>
  group_by(explanatory, explanatory_value, response) |>
  summarise(mean = mean(response_value, na.rm = TRUE),
            low = quantile(response_value, 0.25, na.rm = TRUE),
            high = quantile(response_value, 0.75, na.rm = TRUE) # Source: https://tbradley1013.github.io/2018/10/01/calculating-quantiles-for-groups-with-dplyr-summarize-and-purrr-partial/
            )

# Calculating summary statistics for all
covid_survey_summary_stats_all2 <- covid_survey_longer |>
  group_by(response) |>
  summarise(mean = mean(response_value, na.rm = TRUE),
            low = quantile(response_value, 0.25, na.rm = TRUE),
            high = quantile(response_value, 0.75, na.rm = TRUE)
            ) |>
  mutate(
    explanatory = "All",
    explanatory_value = ""
  )

covid_survey_summary_stats_all2$explanatory_value <- as.factor(as.character(covid_survey_summary_stats_all2$explanatory_value))

sapply(covid_survey_summary_stats_all2, class)

# Bind the two summary statistic dataframes together
covid_survey_summary_stats2 <- bind_rows(covid_survey_summary_stats_all2, covid_survey_summary_stats_by_group2)

# Display tibble
covid_survey_summary_stats2

# Relevel factors
covid_survey_summary_stats2 <- covid_survey_summary_stats2 |>
  mutate(
      explanatory_value = fct_rev(fct_relevel(explanatory_value, ">30", "26-30", "21-25", "<20")),
      explanatory = fct_relevel(explanatory, "All", "exp_age_bin", "exp_gender", "exp_race", "exp_ethnicity", "exp_profession", "exp_already_vax", "exp_flu_vax"),
      explanatory_value = fct_relevel(explanatory_value, "Female", "Male", "Non-binary third gender", "Prefer not to say"),
      explanatory_value = fct_relevel(explanatory_value, "American Indian/Alaskan Native", "Asian", "Black/African American", "Native Hawaiian/Other Pacific Islander", "White"),
      explanatory_value = fct_relevel(explanatory_value, "Non-Hispanic/Non-Latino", "Hispanic/Latino"),
      explanatory_value = fct_relevel(explanatory_value, "Medical", "Nursing"),
      explanatory_value = fct_relevel(explanatory_value, "No", "Yes")
  )

# Set labels
covid_survey_summary_stats2 <- covid_survey_summary_stats2 |>
    mutate(
      explanatory = recode(explanatory, "exp_age_bin" = 'Age', "exp_gender" = 'Gender', "exp_race" = 'Race', "exp_ethnicity" = 'Ethnicity', "exp_profession" = 'Profession', "exp_already_vax" = 'Had COVID vaccine', "exp_flu_vax" = 'Had flu vaccine this year'),
      response = fct_relevel(response, "resp_safety", "resp_feel_safe_at_work", "resp_concern_safety", "resp_confidence_science",   "resp_trust_info", "resp_will_recommend"),
      response = recode(response, 
                        "resp_safety" = 'Based on my understanding, I believe the vaccine is safe', 
                        "resp_confidence_science" = 'I am confident in the scientific vetting process for the new COVID vaccines', 
                        "resp_feel_safe_at_work" = 'Getting the vaccine will make me feel safer at work', 
                        "resp_will_recommend" = 'I will recommend the vaccine to family, friends, and community members', 
                        "resp_trust_info" = 'I trust the information that I have received about the vaccines',
                        "resp_concern_safety" = 'I am concerned about the safety and side effects of the vaccine')
    )

# Creating the plot
covid_survey_summary_stats2 |>
ggplot(aes(x = mean, y = factor(explanatory_value))) +
  geom_point(size = 0.75) +
  geom_errorbarh(aes(xmin = low, xmax = high), height = 0.3) +
  facet_grid(
    rows = vars(explanatory), 
    cols = vars(response), 
    scales = "free_y",
    space = "free_y", 
    labeller = labeller(explanatory = label_wrap_gen(15), response = label_wrap_gen(15)) 
    ) +
  scale_x_continuous(breaks = 1:5) +
  labs(
    x = "Mean Likert score\n(Error bars range from 25th to 75th percentile)",
    y = NULL,
  ) +
  theme(
    strip.text = element_text(size = 6),
    strip.text.y = element_text(angle = 0),
    axis.text.y = element_text(size = 6),
    axis.text.x = element_text(size = 6),
    panel.spacing = unit(0, "lines"),
    panel.spacing.x = unit(0.3, "lines"),
    axis.title.x = element_text(size = 8),
    panel.grid = element_blank(),
    strip.background = element_rect(fill = "gray90", color = "black")
  )
```

This plot drastically differs from that created in question 3. Reducing the percentile range of the error bars by 15 percentile on each end (30 percentiles overall), has significantly shrunk the distribution of the data displayed in the error bar. This definitely impacts interpretations of the plot, as well, as error bars that once spanned the entire Likert scale are now much more concentrated around their respective means due to the changes made. This trend is especially visible in the faceted columns, "I believe the vaccine is safe", and "I am concerned about side effects", which now have much more concentrated error ranges, even when faceted by identity, as well. Interpreting both of these plots side-by-side changes interpretation of these specific columns as we now know more about the distribution of the data, as though we were looking at a violin plot. One interesting finding that remains unchanged between the two plots is that of non-binary third gender respondents' answer to the "I believe the vaccine is safe" question, whose error bar is unchanged. This could be due to a low n, however. Overall, most of these error bars become shorter (or more concentrated), which tells us that these distributions are more concentrated between the 25-75 percentiles than the 10-90 percentiles. This makes complete sense given the Central Limit Theorem which tells us that as n \> 30, distributions will converge to a normal distribution.

## 5 - COVID survey - another view
